{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: 2022-present deepset GmbH <info@deepset.ai>\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "from haystack import Document, component, logging\n",
    "from haystack.components.converters.utils import get_bytestream_from_source, normalize_metadata\n",
    "from haystack.dataclasses import ByteStream\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@component\n",
    "class CSVToDocument:\n",
    "    \"\"\"\n",
    "    Converts CSV files to Documents.\n",
    "\n",
    "    By default, it uses UTF-8 encoding when converting files but\n",
    "    you can also set a custom encoding.\n",
    "    It can attach metadata to the resulting documents.\n",
    "\n",
    "    ### Usage example\n",
    "\n",
    "    ```python\n",
    "    from haystack.components.converters.csv import CSVToDocument\n",
    "    converter = CSVToDocument()\n",
    "    results = converter.run(sources=[\"sample.csv\"], meta={\"date_added\": datetime.now().isoformat()})\n",
    "    documents = results[\"documents\"]\n",
    "    print(documents[0].content)\n",
    "    # 'col1,col2\\now1,row1\\nrow2row2\\n'\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding: str = \"utf-8\"):\n",
    "        \"\"\"\n",
    "        Creates a CSVToDocument component.\n",
    "\n",
    "        :param encoding:\n",
    "            The encoding of the csv files to convert.\n",
    "            If the encoding is specified in the metadata of a source ByteStream,\n",
    "            it overrides this value.\n",
    "        \"\"\"\n",
    "        self.encoding = encoding\n",
    "\n",
    "    @component.output_types(documents=List[Document])\n",
    "    def run(\n",
    "        self,\n",
    "        sources: List[Union[str, Path, ByteStream]],\n",
    "        meta: Optional[Union[Dict[str, Any], List[Dict[str, Any]]]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Converts a CSV file to a Document.\n",
    "\n",
    "        :param sources:\n",
    "            List of file paths or ByteStream objects.\n",
    "        :param meta:\n",
    "            Optional metadata to attach to the documents.\n",
    "            This value can be either a list of dictionaries or a single dictionary.\n",
    "            If it's a single dictionary, its content is added to the metadata of all produced documents.\n",
    "            If it's a list, the length of the list must match the number of sources, because the two lists will\n",
    "            be zipped.\n",
    "            If `sources` contains ByteStream objects, their `meta` will be added to the output documents.\n",
    "        :returns:\n",
    "            A dictionary with the following keys:\n",
    "            - `documents`: Created documents\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "\n",
    "        meta_list = normalize_metadata(meta, sources_count=len(sources))\n",
    "\n",
    "        for source, metadata in zip(sources, meta_list):\n",
    "            try:\n",
    "                bytestream = get_bytestream_from_source(source)\n",
    "            except Exception as e:\n",
    "                logger.warning(\"Could not read {source}. Skipping it. Error: {error}\", source=source, error=e)\n",
    "                continue\n",
    "            try:\n",
    "                encoding = bytestream.meta.get(\"encoding\", self.encoding)\n",
    "                data = io.BytesIO(bytestream.data).getvalue().decode(encoding=encoding)\n",
    "            except Exception as e:\n",
    "                logger.warning(\n",
    "                    \"Could not convert file {source}. Skipping it. Error message: {error}\", source=source, error=e\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            merged_metadata = {**bytestream.meta, **metadata}\n",
    "            document = Document(content=data, meta=merged_metadata)\n",
    "            documents.append(document)\n",
    "\n",
    "        return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x15f3d0390>\n",
       "ðŸš… Components\n",
       "  - converter: CSVToDocument\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: CohereDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - converter.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from helper import load_env\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.pinecone import PineconeDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack_integrations.components.embedders.cohere.document_embedder import CohereDocumentEmbedder\n",
    "warnings.filterwarnings('ignore')\n",
    "load_env()\n",
    "\n",
    "document_store = PineconeDocumentStore(\n",
    "\t\tindex=\"industries\",\n",
    "\t\tnamespace=\"Classification\",\n",
    "        dimension=1024,\n",
    "        spec={\"serverless\": {\"region\": \"us-east-1\", \"cloud\": \"aws\"}},\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"converter\", CSVToDocument())\n",
    "pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"passage\", split_length=10, split_overlap=0))\n",
    "pipeline.add_component(\"embedder\", CohereDocumentEmbedder(model=\"embed-english-v3.0\"))\n",
    "pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "\n",
    "pipeline.connect(\"converter\", \"splitter\")\n",
    "pipeline.connect(\"splitter\", \"embedder\")\n",
    "pipeline.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Upserted vectors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=508.0, output_tokens=None, search_units=None, classifications=None), tokens=None, warnings=[])},\n",
       " 'writer': {'documents_written': 1}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.run(sources=[\"sample.csv\"], meta={\"date_added\": datetime.now().isoformat()})\n",
    "pipeline.run({\"converter\": {\"sources\": [\"Gics_modified_gpt4_v2.csv\"], \"meta\": {}}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
